{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11baf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadind the data\n",
    "df = pd.read_csv(\"/Users/parthgajera/Documents/Thesis_Data/LI-Small_Trans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14276b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f82a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Feature Engineering\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
    "df['SameBank'] = (df['From Bank'] == df['To Bank']).astype(int)\n",
    "df['SameAccount'] = (df['Account'] == df['To Bank']).astype(int)\n",
    "df['CurrencyMismatch'] = (df['Receiving Currency'] != df['Payment Currency']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Frequency of transactions per account\n",
    "df['Txn Count From Account'] = df.groupby('Account')['Timestamp'].transform('count')\n",
    "\n",
    "# Rolling average of amounts from each account\n",
    "df['Rolling Avg From Account'] = df.sort_values(by='Timestamp') \\\n",
    "    .groupby('Account')['Amount Paid'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "\n",
    "# Final Features for Modeling\n",
    "features = [\n",
    "    'Amount Received',\n",
    "    'Amount Paid',\n",
    "    'SameBank',\n",
    "    'SameAccount',\n",
    "    'CurrencyMismatch',\n",
    "    'Txn Count From Account',\n",
    "    'Rolling Avg From Account',\n",
    "    'Payment Format'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "#'Hour','DayOfWeek',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Payment Format']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Isolation Forest pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('iso_forest', IsolationForest(contamination='auto', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X)\n",
    "\n",
    "# Predict anomaly scores and labels\n",
    "X_transformed = pipeline.named_steps['preprocess'].transform(X)\n",
    "df['anomaly_score'] = pipeline.named_steps['iso_forest'].decision_function(X_transformed)\n",
    "df['anomaly_label'] = pipeline.named_steps['iso_forest'].predict(X_transformed)\n",
    "df['anomaly_label'] = df['anomaly_label'].map({1: 'Normal', -1: 'Anomaly'})\n",
    "\n",
    "# Output the flagged anomalies\n",
    "anomalies = df[df['anomaly_label'] == 'Anomaly']\n",
    "print(anomalies[['Timestamp', 'Account', 'Amount Paid', 'anomaly_score']]) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a216d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 2. Building of the pipeline for Isolation Forest\n",
    "# --------------------------------------------\n",
    "# One-hot encode Payment Format while leaving the other features unchanged.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Payment Format']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline with preprocessing and the Isolation Forest\n",
    "iso_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('iso_forest', IsolationForest(contamination='auto', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model on X\n",
    "iso_pipeline.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5981750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 3. Anomaly scores and labels from Isolation Forest\n",
    "# --------------------------------------------\n",
    "# Transform X (apply one-hot encoding on 'Payment Format' and passthrough other features)\n",
    "X_transformed = iso_pipeline.named_steps['preprocess'].transform(X)\n",
    "\n",
    "# Compute the anomaly score and assign the output label\n",
    "df['anomaly_score'] = iso_pipeline.named_steps['iso_forest'].decision_function(X_transformed)\n",
    "df['anomaly_label'] = iso_pipeline.named_steps['iso_forest'].predict(X_transformed)\n",
    "\n",
    "# Map labels from {1, -1} to more interpretable strings if needed\n",
    "df['anomaly_label'] = df['anomaly_label'].map({1: 'Normal', -1: 'Anomaly'})\n",
    "\n",
    "# Print the rows flagged as anomalies by Isolation Forest\n",
    "anomalies = df[df['anomaly_label'] == 'Anomaly']\n",
    "print(\"\\nIsolation Forest flagged anomalies:\")\n",
    "print(anomalies[['Timestamp', 'Account', 'Amount Paid', 'anomaly_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 4. Set up Hybrid Model with XGBoost\n",
    "# --------------------------------------------\n",
    "# The Isolation Forest label as a pseudo target for the XGBoost classifier.\n",
    "# Binary target: 1 for Anomaly, 0 for Normal.\n",
    "label_map = {'Anomaly': 1, 'Normal': 0}\n",
    "df['hybrid_label'] = df['anomaly_label'].map(label_map)\n",
    "\n",
    "# New feature set for the supervised step.\n",
    "# 'Payment Format' is left out here because its encoded version is used by the pipeline;\n",
    "hybrid_features = [\n",
    "    'Amount Received',\n",
    "    'Amount Paid',\n",
    "    'SameBank',\n",
    "    'SameAccount',\n",
    "    'CurrencyMismatch',\n",
    "    'Txn Count From Account',\n",
    "    'Rolling Avg From Account',\n",
    "    'anomaly_score'  # additional feature from Isolation Forest\n",
    "]\n",
    "\n",
    "X_hybrid = df[hybrid_features]\n",
    "y_hybrid = df['hybrid_label']\n",
    "\n",
    "#spliting of the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_hybrid, y_hybrid, test_size=0.2, random_state=42, stratify=y_hybrid)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the hybrid XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"\\nClassification Report for the Hybrid Model (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 5. Hybrid Model Predictions\n",
    "# --------------------------------------------\n",
    "df['hybrid_prediction'] = xgb_model.predict(X_hybrid)\n",
    "df['hybrid_prediction'] = df['hybrid_prediction'].map({1: 'Anomaly', 0: 'Normal'})\n",
    "\n",
    "print(\"\\nSample of Hybrid Model Predictions:\")\n",
    "print(df[['Timestamp', 'Account', 'Amount Paid', 'anomaly_score','Is Laundering', 'hybrid_prediction']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['Is Laundering'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(data=df, x='Timestamp', y='anomaly_score', hue='anomaly_label', palette={'Normal': 'blue', 'Anomaly': 'red'})\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.title('Anomaly Score Over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['anomaly_score'], bins=50, kde=True, color='purple')\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Anomaly Threshold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X_transformed)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=X_2d[:,0], y=X_2d[:,1], hue=df['anomaly_label'], palette={'Normal': 'gray', 'Anomaly': 'red'})\n",
    "plt.title('PCA Visualization of Anomalies')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
